from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import re
import emoji

class SentimentAnalyzer:
    def __init__(self):
        self.model_name = "cointegrated/rubert-tiny-sentiment-balanced"
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)

        self.labels = ['negative', 'neutral', 'positive']
        self.emojis = {'negative': 'üôÅ', 'neutral': 'üòê', 'positive': 'üòä'}

        self.negative_triggers = [
            "–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å", "—É–∂–∞—Å–Ω–æ", "–æ—Ç—Å—Ç–æ–π", "–Ω–µ –∑–∞—à–ª–æ", "–Ω–µ–Ω–∞–≤–∏–∂—É", "—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω", "—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ"
        ]

    def preprocess_emojis(self, text):
        return emoji.demojize(text, delimiters=(" ", " "))

    def clean_text(self, text):
        return re.sub(r'[^\w\s]', '', text.lower())

    def post_correct_label(self, text, label):
        cleaned_text = self.clean_text(text)
        if label == "neutral":
            for phrase in self.negative_triggers:
                if phrase in cleaned_text:
                    return "negative"
        return label

    def analyze(self, text):
        # –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —ç–º–æ–¥–∑–∏
        processed_text = self.preprocess_emojis(text)

        inputs = self.tokenizer(processed_text, return_tensors="pt", truncation=True)
        with torch.no_grad():
            logits = self.model(**inputs).logits
        probs = torch.nn.functional.softmax(logits, dim=1)
        label_idx = torch.argmax(probs, dim=1).item()
        initial_label = self.labels[label_idx]
        confidence = probs[0][label_idx].item()

        # –ü–æ—Å—Ç–∫–æ—Ä—Ä–µ–∫—Ü–∏—è
        corrected_label = self.post_correct_label(text, initial_label)

        return corrected_label, confidence, self.emojis[corrected_label]

    def generate_response(self, label):
        responses = {
            "positive": "–°–ø–∞—Å–∏–±–æ –∑–∞ —Ç—ë–ø–ª—ã–π –æ—Ç–∑—ã–≤! üòä –û—á–µ–Ω—å –ø—Ä–∏—è—Ç–Ω–æ üíñ",
            "neutral": "–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ç–∑—ã–≤! –ï—Å–ª–∏ –µ—Å—Ç—å –∏–¥–µ–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è ‚Äî –Ω–∞–ø–∏—à–∏ üí°",
            "negative": "–ñ–∞–ª—å, —á—Ç–æ –Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å üôÅ –ï—Å–ª–∏ —Ä–∞—Å—Å–∫–∞–∂–µ—à—å –ø–æ–¥—Ä–æ–±–Ω–µ–µ ‚Äî –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∏–º!"
        }
        return responses.get(label, "–°–ø–∞—Å–∏–±–æ –∑–∞ –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å!")

